{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog-cycle-car.png    predicted in  0.417 seconds\n",
      "Objects Detected:    bicycle truck dog\n",
      "----------------------------------------------------------\n",
      "dog.jpg              predicted in  0.417 seconds\n",
      "Objects Detected:    bicycle truck dog\n",
      "----------------------------------------------------------\n",
      "eagle.jpg            predicted in  0.019 seconds\n",
      "Objects Detected:    bird\n",
      "----------------------------------------------------------\n",
      "giraffe.jpg          predicted in  0.019 seconds\n",
      "Objects Detected:    zebra giraffe giraffe\n",
      "----------------------------------------------------------\n",
      "herd_of_horses.jpg   predicted in  0.020 seconds\n",
      "Objects Detected:    horse horse horse horse\n",
      "----------------------------------------------------------\n",
      "img1.jpg             predicted in  0.020 seconds\n",
      "Objects Detected:    person dog\n",
      "----------------------------------------------------------\n",
      "img2.jpg             predicted in  0.023 seconds\n",
      "Objects Detected:    train\n",
      "----------------------------------------------------------\n",
      "img3.jpg             predicted in  0.023 seconds\n",
      "Objects Detected:    car car car car car car car truck traffic light\n",
      "----------------------------------------------------------\n",
      "img4.jpg             predicted in  0.020 seconds\n",
      "Objects Detected:    chair chair chair clock\n",
      "----------------------------------------------------------\n",
      "messi.jpg            predicted in  0.020 seconds\n",
      "Objects Detected:    person person person sports ball\n",
      "----------------------------------------------------------\n",
      "person.jpg           predicted in  0.019 seconds\n",
      "Objects Detected:    person dog horse\n",
      "----------------------------------------------------------\n",
      "scream.jpg           predicted in  0.019 seconds\n",
      "Objects Detected:    \n",
      "----------------------------------------------------------\n",
      "\n",
      "SUMMARY\n",
      "----------------------------------------------------------\n",
      "Task                     : Time Taken (in seconds)\n",
      "\n",
      "Reading addresses        : 0.001\n",
      "Loading batch            : 0.319\n",
      "Detection (12 images)    : 1.112\n",
      "Output Processing        : 0.000\n",
      "Drawing Boxes            : 0.266\n",
      "Average time_per_img     : 0.142\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from utils import *\n",
    "import darknet as dk\n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import os \n",
    "import os.path as osp\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import argparse\n",
    "\n",
    "cuda=True\n",
    "num_classes = 80\n",
    "resolution=416\n",
    "batch_size=2\n",
    "nms_thresh=0.4\n",
    "confidence=0.5\n",
    "images='images/'\n",
    "det='det/'\n",
    "link=\"cfg/yolov3.cfg\"\n",
    "model = dk.Darknet(link)\n",
    "model.load_weights(\"weights/yolov3.weights\")\n",
    "classes=load_classes('data/coco.names')\n",
    "\n",
    "model.net_params['height'] = resolution\n",
    "inp_dim = int(model.net_params['height'])\n",
    "assert inp_dim % 32 == 0 \n",
    "assert inp_dim > 32\n",
    "\n",
    "model=model.to(get_device())\n",
    "model.eval()\n",
    "\n",
    "\n",
    "read_dir=time.time()\n",
    "try:\n",
    "    imlist= [osp.join(osp.realpath('.'), images, img) for img in os.listdir(images) if os.path.splitext(img)[1] == '.png'\n",
    "             or os.path.splitext(img)[1] =='.jpeg' or os.path.splitext(img)[1] =='.jpg']\n",
    "except NotADirectoryError:\n",
    "    imlist=[]\n",
    "    imlist.append(osp.join(osp.realpath('.'),images))\n",
    "except FileNotFoundError:\n",
    "    print('no file found')\n",
    "\n",
    "if not os.path.exists(det):\n",
    "    os.makedirs(det)\n",
    "\n",
    "load_batch=time.time()\n",
    "#loaded_ims=[cv2.imread(x) for x in imlist]\n",
    "#loaded_ims=[letterbox_image(cv2.imread(x),[inp_dim for x in range(len(imlist))]) for x in loaded_ims]\n",
    "#loaded_ims=list(map(letterbox_image,loaded_ims,[inp_dim for x in range(len(imlist))]))\n",
    "loaded_imgs = [cv2.imread(x) for x in imlist]\n",
    "\n",
    "batches=list(map(prep_image,imlist,[inp_dim for x in range(len(imlist))]))\n",
    "\n",
    "img_batches=[x[0] for x in batches]\n",
    "orig_imgs=[x[1] for x in batches]\n",
    "img_dim_list=[x[2] for x in batches]\n",
    "img_dim_list=torch.FloatTensor(img_dim_list).repeat(1,2)\n",
    "img_dim_list=img_dim_list.to(get_device())\n",
    "\n",
    "\n",
    "leftover=0\n",
    "if(len(img_dim_list)%batch_size):\n",
    "    leftover=1\n",
    "    \n",
    "if batch_size!=1:\n",
    "    num_batches=len(imlist)//batch_size+leftover\n",
    "    img_batches=[torch.cat((img_batches[i*batch_size:min((i+1)*batch_size,len(img_batches))])) for i in range(num_batches)]\n",
    "    \n",
    "i=0\n",
    "write=False\n",
    "\n",
    "start_det_loop=time.time()\n",
    "objs={}\n",
    "\n",
    "for batch in img_batches:\n",
    "    start=time.time()\n",
    "    \n",
    "    batch=batch.to(get_device())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #model=model.to(get_device())\n",
    "        prediction=model(Variable(batch))\n",
    "    #print(prediction) \n",
    "    prediction=write_results(prediction,confidence,num_classes,nms_thresh)\n",
    "    \n",
    "    if type(prediction)==int:\n",
    "        i+=1\n",
    "        continue\n",
    "        \n",
    "    end=time.time()\n",
    "    \n",
    "    prediction[:,0]+=i*batch_size\n",
    "    \n",
    "    if not write:\n",
    "        output=prediction\n",
    "        write=1\n",
    "    else:\n",
    "        output=torch.cat((output,prediction))\n",
    "    \n",
    "    for img_num,image in enumerate(imlist[i*batch_size:min((i+1)*batch_size,len(imlist))]):\n",
    "        img_id=i*batch_size+img_num\n",
    "        objs=[classes[int(x[-1])] for x in output if int(x[0])==img_id]\n",
    "        \n",
    "        print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
    "        print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
    "        print(\"----------------------------------------------------------\")\n",
    "        \n",
    "    i += 1\n",
    "    if cuda:\n",
    "        torch.cuda.synchronize()\n",
    "try:\n",
    "    output\n",
    "except NameError:\n",
    "    print('no detections')\n",
    "        \n",
    "    \n",
    "img_dim_list=torch.index_select(img_dim_list,0,output[:,0].long())\n",
    "scaling_factor=torch.min(inp_dim/img_dim_list,1)[0].view(-1,1)\n",
    "    \n",
    "output[:,[1,3]]-=(inp_dim-scaling_factor*img_dim_list[:,0].view(-1,1))/2\n",
    "output[:,[2,4]]-=(inp_dim-scaling_factor*img_dim_list[:,1].view(-1,1))/2\n",
    "    \n",
    "output[:,1:5] /= scaling_factor\n",
    "    \n",
    "for i in range(output.shape[0]):\n",
    "    output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, img_dim_list[i,0])\n",
    "    output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, img_dim_list[i,1])\n",
    "        \n",
    "output_recast = time.time()\n",
    "class_load = time.time()\n",
    "colors=pkl.load(open('pallete','rb'))\n",
    "    \n",
    "draw=time.time()\n",
    "    \n",
    "\n",
    "    \n",
    "list(map(lambda x: apply_box(x,orig_imgs,classes,colors),output))\n",
    "\n",
    "det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(det,x.split(\"/\")[-1]))\n",
    "    \n",
    "list(map(cv2.imwrite, det_names, orig_imgs))\n",
    "    \n",
    "end = time.time()\n",
    "    \n",
    "print()\n",
    "print(\"SUMMARY\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
    "print()\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\", load_batch - read_dir))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", start_det_loop - load_batch))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Detection (\" + str(len(imlist)) +  \" images)\", output_recast - start_det_loop))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Output Processing\", class_load - output_recast))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", end - draw))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end - load_batch)/len(imlist)))\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "    \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
