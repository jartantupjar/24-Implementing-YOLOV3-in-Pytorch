{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from utils import *\n",
    "import darknet as dk\n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import os \n",
    "import os.path as osp\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "#from pycocotools.coco import COCO\n",
    "import json\n",
    "from skimage.transform import resize\n",
    "import data_augmentation\n",
    "\n",
    "class CoCoDataset(data.Dataset):\n",
    "    def __init__(self,img_folder,resolution,append_label='images',is_training=True):\n",
    "        self.resolution=(resolution,resolution)\n",
    "        self.is_training=is_training\n",
    "        self.append_label=append_label\n",
    "        with open(img_folder,'r') as f:\n",
    "            self.img_files=f.readlines()\n",
    "        self.labels=[path.replace('images', 'labels').replace('.png', '.txt').replace('.jpg', '.txt') for path in self.img_files]\n",
    "        self.max_objs=50\n",
    "        self.transform=data_augmentation.Compose()\n",
    "        if self.is_training:\n",
    "           \n",
    "            self.transform.add(data_augmentation.ImageBaseAug())\n",
    "        self.transform.add(data_augmentation.ResizeImage(self.resolution))    \n",
    "        self.transform.add(data_augmentation.ToTensor(self.max_objs))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_path=self.img_files[idx%len(self.img_files)].rstrip()\n",
    "        img_path=self.append_label+img_path\n",
    "        #img=Image.open(img_path).convert('RGB')\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label_path=self.labels[idx%len(self.img_files)].rstrip()\n",
    "        label_path=self.append_label+label_path\n",
    "        if os.path.exists(label_path):\n",
    "            labels = np.loadtxt(label_path).reshape(-1, 5)\n",
    "        else:\n",
    "            print('oof',label_path)\n",
    "            labels = np.zeros((1, 5), np.float32)\n",
    "        \n",
    "        sample = {'image': img, 'label': labels}\n",
    "        if self.transform is not None:\n",
    "            sample=self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    def getitem(self, idx):\n",
    "        img_path=self.img_files[idx%len(self.img_files)].rstrip()\n",
    "        #print(img_path)\n",
    "        img_path=self.append_label+img_path\n",
    "        img=np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        #print(img.shape)\n",
    "        h,w,_=img.shape\n",
    "        dim_diff=np.abs(h-w)\n",
    "        pad1,pad2=dim_diff//2,dim_diff-dim_diff//2\n",
    "        pad=((pad1,pad2),(0,0),(0,0)) if h<=w else((0,0),(pad1,pad2),(0,0))\n",
    "        #input_img=np.pad(img,pad,'constant',constant_values=128)/255.0\n",
    "        #input_img=transforms.functional.pad(img,pad,'constant',128)/255.\n",
    "        padded_h,padded_w,_=img.shape\n",
    "        #input_img=transforms.functional.resize(input_img,self.resolution)\n",
    "        input_img =resize(img, (*self.resolution, 3), mode='reflect')\n",
    "        input_img = np.transpose(input_img, (2, 0, 1))\n",
    "        input_img = torch.from_numpy(input_img).float()\n",
    "\n",
    "        label_path=self.labels[idx%len(self.img_files)].rstrip()\n",
    "        \n",
    "        labels=None\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            labels = np.loadtxt(label_path).reshape(-1, 5)\n",
    "            \n",
    "            x1 = w * (labels[:, 1] - labels[:, 3]/2)\n",
    "            y1 = h * (labels[:, 2] - labels[:, 4]/2)\n",
    "            x2 = w * (labels[:, 1] + labels[:, 3]/2)\n",
    "            y2 = h * (labels[:, 2] + labels[:, 4]/2)\n",
    "    \n",
    "            x1 += pad[1][0]\n",
    "            y1 += pad[0][0]\n",
    "            x2 += pad[1][0]\n",
    "            y2 += pad[0][0]\n",
    "            \n",
    "            labels[:, 1] = ((x1 + x2) / 2) / padded_w\n",
    "            labels[:, 2] = ((y1 + y2) / 2) / padded_h\n",
    "            labels[:, 3] *= w / padded_w\n",
    "            labels[:, 4] *= h / padded_h\n",
    "            \n",
    "        filled_labels=np.zeros((self.max_objs,5))\n",
    "        \n",
    "        if labels is not None:\n",
    "            \n",
    "            filled_labels[range(len(labels))[:self.max_objs]]=labels[:self.max_objs]\n",
    "            \n",
    "        filled_labels=torch.from_numpy(filled_labels)\n",
    "        \n",
    "        return img_path,input_img,filled_labels\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2, Batch 0/11727] [Losses: x 0.257722, y 0.279835, w 4.472505, h 5.426966, conf nan, cls 1.316923, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 1/11727] [Losses: x 0.269594, y 0.249322, w 10.645700, h 10.392942, conf nan, cls 1.315169, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 2/11727] [Losses: x 0.283745, y 0.282023, w 5.017067, h 5.504388, conf nan, cls 1.312805, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 3/11727] [Losses: x 0.318707, y 0.274200, w 6.617477, h 7.204269, conf nan, cls 1.301341, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 4/11727] [Losses: x 0.250352, y 0.266185, w 3.072226, h 4.389412, conf nan, cls 1.307905, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 5/11727] [Losses: x 0.275028, y 0.196782, w 3.860775, h 5.318764, conf nan, cls 1.309470, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 6/11727] [Losses: x 0.274168, y 0.286597, w 6.242350, h 4.622346, conf nan, cls 1.295728, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 7/11727] [Losses: x 0.280953, y 0.311187, w 1.970655, h 2.361192, conf nan, cls 1.310397, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 8/11727] [Losses: x 0.230310, y 0.230131, w 2.308765, h 2.746310, conf nan, cls 1.305270, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 9/11727] [Losses: x 0.268484, y 0.245766, w 2.245203, h 2.188880, conf nan, cls 1.295247, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 10/11727] [Losses: x 0.213623, y 0.246465, w 2.217691, h 3.341959, conf nan, cls 1.295962, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 11/11727] [Losses: x 0.291662, y 0.240450, w 3.239681, h 2.970583, conf nan, cls 1.286532, total nan, recall: 0.00725, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 12/11727] [Losses: x 0.253933, y 0.249050, w 2.051182, h 2.219780, conf nan, cls 1.288222, total nan, recall: 0.00444, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 13/11727] [Losses: x 0.248746, y 0.243597, w 2.029426, h 2.250824, conf nan, cls 1.291887, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 14/11727] [Losses: x 0.283153, y 0.269937, w 3.924703, h 2.634114, conf nan, cls 1.286304, total nan, recall: 0.00855, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 15/11727] [Losses: x 0.253362, y 0.267110, w 1.730568, h 1.676907, conf nan, cls 1.290773, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 16/11727] [Losses: x 0.253547, y 0.254497, w 1.633851, h 2.279928, conf nan, cls 1.281209, total nan, recall: 0.00463, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 17/11727] [Losses: x 0.283083, y 0.271601, w 1.920811, h 2.575857, conf nan, cls 1.289356, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 18/11727] [Losses: x 0.253598, y 0.252160, w 1.497136, h 2.896524, conf nan, cls 1.289715, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 19/11727] [Losses: x 0.245419, y 0.245219, w 1.939913, h 2.277271, conf nan, cls 1.265880, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 20/11727] [Losses: x 0.240087, y 0.219988, w 2.775239, h 1.397298, conf nan, cls 1.293814, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 21/11727] [Losses: x 0.223258, y 0.249263, w 1.660236, h 2.226474, conf nan, cls 1.270363, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 22/11727] [Losses: x 0.263089, y 0.240587, w 3.443198, h 3.857262, conf nan, cls 1.289823, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 23/11727] [Losses: x 0.260661, y 0.254349, w 1.911197, h 1.797299, conf nan, cls 1.269390, total nan, recall: 0.00366, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 24/11727] [Losses: x 0.245551, y 0.225184, w 2.250241, h 2.499173, conf nan, cls 1.259611, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 25/11727] [Losses: x 0.228060, y 0.261613, w 2.085653, h 1.887057, conf nan, cls 1.261260, total nan, recall: 0.00483, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 26/11727] [Losses: x 0.262918, y 0.262086, w 2.115589, h 1.671383, conf nan, cls 1.283639, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 27/11727] [Losses: x 0.257654, y 0.242239, w 2.024486, h 1.905630, conf nan, cls 1.260881, total nan, recall: 0.00673, precision: 0.00013]\n",
      "[Epoch 0/2, Batch 28/11727] [Losses: x 0.284153, y 0.241607, w 1.427885, h 1.893636, conf nan, cls 1.280668, total nan, recall: 0.00585, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 29/11727] [Losses: x 0.251902, y 0.252086, w 2.469590, h 2.651669, conf nan, cls 1.272094, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 30/11727] [Losses: x 0.228753, y 0.277959, w 1.915241, h 1.709824, conf nan, cls 1.277475, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 31/11727] [Losses: x 0.237295, y 0.286890, w 1.787532, h 2.251200, conf nan, cls 1.265522, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 32/11727] [Losses: x 0.261504, y 0.246958, w 1.710155, h 2.241486, conf nan, cls 1.258585, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 33/11727] [Losses: x 0.271960, y 0.256942, w 1.752963, h 1.882267, conf nan, cls 1.262971, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 34/11727] [Losses: x 0.245591, y 0.263365, w 1.929435, h 2.254121, conf nan, cls 1.231987, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 35/11727] [Losses: x 0.269556, y 0.220258, w 2.303380, h 1.502454, conf nan, cls 1.263007, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 36/11727] [Losses: x 0.264214, y 0.255084, w 1.686603, h 1.828346, conf nan, cls 1.225132, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 37/11727] [Losses: x 0.243346, y 0.253844, w 1.415196, h 1.800704, conf nan, cls 1.254817, total nan, recall: 0.00197, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 38/11727] [Losses: x 0.242638, y 0.221284, w 1.608005, h 1.854152, conf nan, cls 1.229616, total nan, recall: 0.00667, precision: 0.00013]\n",
      "[Epoch 0/2, Batch 39/11727] [Losses: x 0.242345, y 0.244149, w 1.601642, h 2.478890, conf nan, cls 1.246473, total nan, recall: 0.00647, precision: 0.00002]\n",
      "[Epoch 0/2, Batch 40/11727] [Losses: x 0.254281, y 0.231321, w 2.561046, h 1.808915, conf nan, cls 1.235346, total nan, recall: 0.01170, precision: 0.00013]\n",
      "[Epoch 0/2, Batch 41/11727] [Losses: x 0.284895, y 0.269418, w 1.225207, h 1.830429, conf nan, cls 1.232317, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 42/11727] [Losses: x 0.249782, y 0.249681, w 1.755841, h 1.752335, conf nan, cls 1.261559, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 43/11727] [Losses: x 0.273914, y 0.268687, w 2.158156, h 2.053010, conf nan, cls 1.251034, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 44/11727] [Losses: x 0.258916, y 0.236084, w 1.570289, h 1.698787, conf nan, cls 1.215567, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 45/11727] [Losses: x 0.260761, y 0.280346, w 2.359646, h 2.585960, conf nan, cls 1.237295, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 46/11727] [Losses: x 0.253366, y 0.278386, w 1.748542, h 1.533544, conf nan, cls 1.208963, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 47/11727] [Losses: x 0.247773, y 0.254709, w 1.825962, h 1.442017, conf nan, cls 1.239099, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 48/11727] [Losses: x 0.236089, y 0.271271, w 1.489921, h 2.130061, conf nan, cls 1.269947, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 49/11727] [Losses: x 0.258434, y 0.284118, w 1.629575, h 2.139866, conf nan, cls 1.250136, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 50/11727] [Losses: x 0.259181, y 0.233615, w 1.515558, h 1.551794, conf nan, cls 1.233425, total nan, recall: 0.00654, precision: 0.00008]\n",
      "[Epoch 0/2, Batch 51/11727] [Losses: x 0.243265, y 0.242529, w 1.516540, h 2.098291, conf nan, cls 1.237129, total nan, recall: 0.00855, precision: 0.00008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2, Batch 52/11727] [Losses: x 0.255493, y 0.258187, w 2.748450, h 2.189387, conf nan, cls 1.222862, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 53/11727] [Losses: x 0.250321, y 0.257098, w 1.636530, h 1.779845, conf nan, cls 1.203371, total nan, recall: 0.00709, precision: 0.00013]\n",
      "[Epoch 0/2, Batch 54/11727] [Losses: x 0.286702, y 0.261844, w 2.129825, h 2.227146, conf nan, cls 1.242885, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 55/11727] [Losses: x 0.265780, y 0.244120, w 1.684720, h 2.173025, conf nan, cls 1.232825, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 56/11727] [Losses: x 0.263053, y 0.279834, w 3.250091, h 2.766753, conf nan, cls 1.226277, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 57/11727] [Losses: x 0.261485, y 0.239969, w 1.924506, h 3.363768, conf nan, cls 1.253835, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 58/11727] [Losses: x 0.252244, y 0.243110, w 1.878493, h 2.191230, conf nan, cls 1.230863, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 59/11727] [Losses: x 0.305918, y 0.244859, w 1.916628, h 1.757652, conf nan, cls 1.218741, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 60/11727] [Losses: x 0.249342, y 0.243993, w 1.223448, h 1.837771, conf nan, cls 1.221030, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 61/11727] [Losses: x 0.268826, y 0.267894, w 1.609678, h 2.047209, conf nan, cls 1.276586, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 62/11727] [Losses: x 0.285758, y 0.281997, w 1.620315, h 1.884808, conf nan, cls 1.233297, total nan, recall: 0.00952, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 63/11727] [Losses: x 0.229108, y 0.234704, w 2.300114, h 2.049755, conf nan, cls 1.256285, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 64/11727] [Losses: x 0.239174, y 0.254200, w 1.497756, h 2.063172, conf nan, cls 1.222997, total nan, recall: 0.00833, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 65/11727] [Losses: x 0.265407, y 0.263164, w 1.992160, h 2.028752, conf nan, cls 1.230235, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 66/11727] [Losses: x 0.247639, y 0.239754, w 2.477637, h 1.448032, conf nan, cls 1.226435, total nan, recall: 0.00407, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 67/11727] [Losses: x 0.263691, y 0.229971, w 2.167151, h 2.012766, conf nan, cls 1.222102, total nan, recall: 0.00939, precision: 0.00008]\n",
      "[Epoch 0/2, Batch 68/11727] [Losses: x 0.255421, y 0.218156, w 1.437642, h 1.667916, conf nan, cls 1.211845, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 69/11727] [Losses: x 0.245834, y 0.263889, w 1.910099, h 1.800466, conf nan, cls 1.229234, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 70/11727] [Losses: x 0.250292, y 0.279829, w 2.165768, h 2.183418, conf nan, cls 1.193563, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 71/11727] [Losses: x 0.285740, y 0.296572, w 1.815917, h 1.664094, conf nan, cls 1.221563, total nan, recall: 0.01333, precision: 0.00013]\n",
      "[Epoch 0/2, Batch 72/11727] [Losses: x 0.275123, y 0.244045, w 1.628720, h 1.819552, conf nan, cls 1.226231, total nan, recall: 0.00330, precision: 0.00002]\n",
      "[Epoch 0/2, Batch 73/11727] [Losses: x 0.237154, y 0.250212, w 2.044257, h 2.355825, conf nan, cls 1.213089, total nan, recall: 0.00617, precision: 0.00020]\n",
      "[Epoch 0/2, Batch 74/11727] [Losses: x 0.230251, y 0.259647, w 1.925703, h 1.782405, conf nan, cls 1.241911, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 75/11727] [Losses: x 0.270786, y 0.237370, w 1.951501, h 2.973347, conf nan, cls 1.205741, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 76/11727] [Losses: x 0.240627, y 0.237310, w 1.637570, h 1.993777, conf nan, cls 1.210168, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 77/11727] [Losses: x 0.256219, y 0.239175, w 1.620234, h 1.188447, conf nan, cls 1.245312, total nan, recall: 0.00383, precision: 0.00002]\n",
      "[Epoch 0/2, Batch 78/11727] [Losses: x 0.281984, y 0.244825, w 1.718485, h 1.689435, conf nan, cls 1.210891, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 79/11727] [Losses: x 0.246228, y 0.253971, w 1.594335, h 2.007648, conf nan, cls 1.225131, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 80/11727] [Losses: x 0.255109, y 0.245836, w 2.124420, h 1.788835, conf nan, cls 1.195069, total nan, recall: 0.00388, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 81/11727] [Losses: x 0.250531, y 0.264503, w 1.946329, h 1.417025, conf nan, cls 1.221303, total nan, recall: 0.00321, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 82/11727] [Losses: x 0.247457, y 0.263378, w 1.505231, h 1.986184, conf nan, cls 1.187778, total nan, recall: 0.00457, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 83/11727] [Losses: x 0.233225, y 0.249773, w 1.559577, h 2.004619, conf nan, cls 1.204369, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 84/11727] [Losses: x 0.224516, y 0.267649, w 2.239938, h 2.508082, conf nan, cls 1.213075, total nan, recall: 0.00794, precision: 0.00013]\n",
      "[Epoch 0/2, Batch 85/11727] [Losses: x 0.249924, y 0.257906, w 1.569889, h 2.030441, conf nan, cls 1.253471, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 86/11727] [Losses: x 0.214911, y 0.281698, w 1.941334, h 2.423419, conf nan, cls 1.173120, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 87/11727] [Losses: x 0.251664, y 0.249820, w 1.615299, h 1.499557, conf nan, cls 1.218222, total nan, recall: 0.00412, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 88/11727] [Losses: x 0.237113, y 0.289760, w 2.022858, h 3.263141, conf nan, cls 1.244091, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 89/11727] [Losses: x 0.240639, y 0.267207, w 1.279295, h 2.162680, conf nan, cls 1.249085, total nan, recall: 0.00392, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 90/11727] [Losses: x 0.246174, y 0.243771, w 1.878508, h 1.472237, conf nan, cls 1.216475, total nan, recall: 0.00709, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 91/11727] [Losses: x 0.205047, y 0.269527, w 1.133069, h 1.323106, conf nan, cls 1.212587, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 92/11727] [Losses: x 0.240248, y 0.266431, w 2.608277, h 2.101359, conf nan, cls 1.181937, total nan, recall: 0.00733, precision: 0.00013]\n",
      "[Epoch 0/2, Batch 93/11727] [Losses: x 0.271971, y 0.291313, w 3.515973, h 3.428612, conf nan, cls 1.227218, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 94/11727] [Losses: x 0.219819, y 0.253885, w 1.453731, h 1.475631, conf nan, cls 1.244793, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 95/11727] [Losses: x 0.239183, y 0.230436, w 1.323051, h 1.692048, conf nan, cls 1.265203, total nan, recall: 0.00483, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 96/11727] [Losses: x 0.239117, y 0.259138, w 1.423883, h 1.737021, conf nan, cls 1.185134, total nan, recall: 0.00358, precision: 0.00002]\n",
      "[Epoch 0/2, Batch 97/11727] [Losses: x 0.235750, y 0.248277, w 1.283982, h 1.918954, conf nan, cls 1.262209, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 98/11727] [Losses: x 0.288236, y 0.290796, w 1.581830, h 1.987845, conf nan, cls 1.207882, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 99/11727] [Losses: x 0.272645, y 0.227772, w 1.562921, h 1.646570, conf nan, cls 1.221308, total nan, recall: 0.00565, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 100/11727] [Losses: x 0.281784, y 0.264614, w 1.895261, h 1.453058, conf nan, cls 1.172209, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 101/11727] [Losses: x 0.228936, y 0.287264, w 3.179606, h 2.614484, conf nan, cls 1.177604, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 102/11727] [Losses: x 0.290337, y 0.287234, w 1.549883, h 1.927894, conf nan, cls 1.215239, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 103/11727] [Losses: x 0.238995, y 0.262415, w 2.075740, h 2.412751, conf nan, cls 1.186629, total nan, recall: 0.00000, precision: 0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2, Batch 104/11727] [Losses: x 0.213042, y 0.242136, w 1.350549, h 1.550060, conf nan, cls 1.244006, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 105/11727] [Losses: x 0.264991, y 0.272113, w 2.450437, h 2.570612, conf nan, cls 1.246646, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 106/11727] [Losses: x 0.260778, y 0.246536, w 1.718672, h 1.456600, conf nan, cls 1.198278, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 107/11727] [Losses: x 0.273327, y 0.242434, w 1.439824, h 1.736636, conf nan, cls 1.214607, total nan, recall: 0.00388, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 108/11727] [Losses: x 0.262471, y 0.244555, w 1.873188, h 1.159895, conf nan, cls 1.285792, total nan, recall: 0.01010, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 109/11727] [Losses: x 0.296456, y 0.276235, w 1.278335, h 1.785548, conf nan, cls 1.224509, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 110/11727] [Losses: x 0.253863, y 0.253648, w 1.473285, h 2.459044, conf nan, cls 1.242589, total nan, recall: 0.00538, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 111/11727] [Losses: x 0.268199, y 0.270967, w 1.770772, h 2.476109, conf nan, cls 1.238487, total nan, recall: 0.02273, precision: 0.00015]\n",
      "[Epoch 0/2, Batch 112/11727] [Losses: x 0.257622, y 0.268427, w 1.561226, h 1.137143, conf nan, cls 1.165134, total nan, recall: 0.00324, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 113/11727] [Losses: x 0.254859, y 0.245453, w 2.188960, h 3.196290, conf nan, cls 1.165086, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 114/11727] [Losses: x 0.268485, y 0.237335, w 1.241729, h 1.580908, conf nan, cls 1.214776, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 115/11727] [Losses: x 0.270430, y 0.236896, w 1.876967, h 1.859912, conf nan, cls 1.192792, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 116/11727] [Losses: x 0.248141, y 0.266575, w 1.872178, h 2.312662, conf nan, cls 1.204427, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 117/11727] [Losses: x 0.277799, y 0.254983, w 1.905483, h 1.928666, conf nan, cls 1.256146, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 118/11727] [Losses: x 0.233519, y 0.256335, w 1.339014, h 2.123813, conf nan, cls 1.215427, total nan, recall: 0.00606, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 119/11727] [Losses: x 0.247720, y 0.240346, w 1.371397, h 2.090787, conf nan, cls 1.218432, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 120/11727] [Losses: x 0.246800, y 0.268439, w 1.390283, h 1.755631, conf nan, cls 1.169824, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 121/11727] [Losses: x 0.262125, y 0.256562, w 1.763989, h 1.709784, conf nan, cls 1.228201, total nan, recall: 0.00422, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 122/11727] [Losses: x 0.222269, y 0.255476, w 1.754535, h 1.902321, conf nan, cls 1.240217, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 123/11727] [Losses: x 0.259305, y 0.247188, w 1.726153, h 2.928002, conf nan, cls 1.254398, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 124/11727] [Losses: x 0.286626, y 0.225319, w 2.267751, h 1.874626, conf nan, cls 1.238446, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 125/11727] [Losses: x 0.264106, y 0.263404, w 1.462283, h 2.302376, conf nan, cls 1.219569, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 126/11727] [Losses: x 0.230428, y 0.244460, w 1.634114, h 1.713792, conf nan, cls 1.224028, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 127/11727] [Losses: x 0.248676, y 0.228002, w 1.257903, h 1.065633, conf nan, cls 1.221555, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 128/11727] [Losses: x 0.249514, y 0.245531, w 2.032518, h 3.377249, conf nan, cls 1.213615, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 129/11727] [Losses: x 0.283548, y 0.259267, w 2.197349, h 1.480900, conf nan, cls 1.251233, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 130/11727] [Losses: x 0.281891, y 0.201038, w 2.846606, h 2.424594, conf nan, cls 1.213818, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 131/11727] [Losses: x 0.254508, y 0.269570, w 2.090934, h 1.597100, conf nan, cls 1.199463, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 132/11727] [Losses: x 0.256673, y 0.261856, w 1.786788, h 1.609243, conf nan, cls 1.188010, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 133/11727] [Losses: x 0.267381, y 0.243558, w 1.283297, h 1.733897, conf nan, cls 1.208737, total nan, recall: 0.00321, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 134/11727] [Losses: x 0.267772, y 0.245432, w 1.710693, h 1.847655, conf nan, cls 1.179470, total nan, recall: 0.00412, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 135/11727] [Losses: x 0.303286, y 0.269263, w 1.574179, h 2.315031, conf nan, cls 1.252936, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 136/11727] [Losses: x 0.242845, y 0.244322, w 1.531787, h 1.913617, conf nan, cls 1.237866, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 137/11727] [Losses: x 0.229753, y 0.258817, w 1.809006, h 2.346958, conf nan, cls 1.227151, total nan, recall: 0.00469, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 138/11727] [Losses: x 0.291261, y 0.267251, w 3.352096, h 2.318839, conf nan, cls 1.202892, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 139/11727] [Losses: x 0.288612, y 0.229997, w 2.198335, h 1.890971, conf nan, cls 1.203595, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 140/11727] [Losses: x 0.304203, y 0.283999, w 1.770609, h 1.804712, conf nan, cls 1.259735, total nan, recall: 0.00546, precision: 0.00002]\n",
      "[Epoch 0/2, Batch 141/11727] [Losses: x 0.242884, y 0.263948, w 1.590979, h 1.667915, conf nan, cls 1.238050, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 142/11727] [Losses: x 0.254144, y 0.267219, w 1.799982, h 1.335972, conf nan, cls 1.213859, total nan, recall: 0.00463, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 143/11727] [Losses: x 0.244429, y 0.283816, w 2.544283, h 2.621277, conf nan, cls 1.172988, total nan, recall: 0.00422, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 144/11727] [Losses: x 0.235980, y 0.280213, w 1.310106, h 2.095849, conf nan, cls 1.183743, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 145/11727] [Losses: x 0.239889, y 0.282631, w 1.700031, h 1.808157, conf nan, cls 1.215658, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 146/11727] [Losses: x 0.246432, y 0.253329, w 1.649950, h 2.036966, conf nan, cls 1.216487, total nan, recall: 0.00317, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 147/11727] [Losses: x 0.280320, y 0.255423, w 1.632015, h 1.110383, conf nan, cls 1.255295, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 148/11727] [Losses: x 0.220537, y 0.244644, w 1.277350, h 1.685544, conf nan, cls 1.184297, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 149/11727] [Losses: x 0.238845, y 0.275419, w 1.627209, h 1.695134, conf nan, cls 1.196032, total nan, recall: 0.01471, precision: 0.00020]\n",
      "[Epoch 0/2, Batch 150/11727] [Losses: x 0.303436, y 0.249792, w 2.823817, h 1.885708, conf nan, cls 1.220941, total nan, recall: 0.01515, precision: 0.00007]\n",
      "[Epoch 0/2, Batch 151/11727] [Losses: x 0.233011, y 0.261488, w 2.377458, h 1.599201, conf nan, cls 1.157242, total nan, recall: 0.00660, precision: 0.00013]\n",
      "[Epoch 0/2, Batch 152/11727] [Losses: x 0.247406, y 0.228143, w 1.814561, h 1.494257, conf nan, cls 1.163074, total nan, recall: 0.01258, precision: 0.00013]\n",
      "[Epoch 0/2, Batch 153/11727] [Losses: x 0.230657, y 0.252944, w 2.102148, h 2.521168, conf nan, cls 1.214807, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 154/11727] [Losses: x 0.288751, y 0.241248, w 1.810817, h 2.151104, conf nan, cls 1.188956, total nan, recall: 0.00000, precision: 0.00000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/2, Batch 155/11727] [Losses: x 0.266252, y 0.226580, w 1.525339, h 1.338585, conf nan, cls 1.243003, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 156/11727] [Losses: x 0.245251, y 0.256023, w 1.692845, h 2.389308, conf nan, cls 1.176560, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 157/11727] [Losses: x 0.267879, y 0.298606, w 2.158817, h 2.424874, conf nan, cls 1.239380, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 158/11727] [Losses: x 0.232013, y 0.267737, w 1.652735, h 1.980598, conf nan, cls 1.211339, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 159/11727] [Losses: x 0.253478, y 0.220274, w 1.661729, h 1.798116, conf nan, cls 1.229875, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 160/11727] [Losses: x 0.237596, y 0.264744, w 1.739470, h 2.864066, conf nan, cls 1.187111, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 161/11727] [Losses: x 0.249212, y 0.255427, w 1.942722, h 1.555326, conf nan, cls 1.237445, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 162/11727] [Losses: x 0.253107, y 0.247789, w 1.879035, h 2.969170, conf nan, cls 1.231133, total nan, recall: 0.00000, precision: 0.00000]\n",
      "[Epoch 0/2, Batch 163/11727] [Losses: x 0.257670, y 0.329261, w 1.395250, h 1.614345, conf nan, cls 1.215373, total nan, recall: 0.00000, precision: 0.00000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4bdc41c7b265>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCoCoDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_imgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresolution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-4a7af8d65058>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend_label\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m#img=Image.open(img_path).convert('RGB')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cuda=True\n",
    "num_classes = 80\n",
    "batch_size=10\n",
    "resolution=416\n",
    "nms_thresh=0.6\n",
    "confidence=0.5\n",
    "resolution=416\n",
    "#input_imgs='images/'\n",
    "#input_imgs='data/coco/trainvalno5k.txt'\n",
    "input_imgs='images/trainvalno5k.txt'\n",
    "link=\"cfg/yolov3.cfg\"\n",
    "\n",
    "is_training=True\n",
    "epochs=2\n",
    "\n",
    "\n",
    "model=dk.Darknet(link)\n",
    "#model.apply()\n",
    "model=model.to(get_device())\n",
    "model.train()\n",
    "\n",
    "#Tensor=torch.FloatTensor.to(get_device())\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "optimizer=torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()))\n",
    "dataloader = data.DataLoader(CoCoDataset(input_imgs,resolution,is_training=is_training),batch_size=batch_size,shuffle=False, pin_memory=False)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_i, sample in enumerate(dataloader):\n",
    "            imgs=sample['image']\n",
    "            targets=sample['label']\n",
    "            imgs = Variable(imgs.type(Tensor))\n",
    "            targets = Variable(targets.type(Tensor), requires_grad=False)\n",
    "            optimizer.zero_grad()\n",
    "           #print(targets)\n",
    "            loss=model(imgs,targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(\n",
    "                \"[Epoch %d/%d, Batch %d/%d] [Losses: x %f, y %f, w %f, h %f, conf %f, cls %f, total %f, recall: %.5f, precision: %.5f]\"\n",
    "                % (\n",
    "                    epoch,\n",
    "                    epochs,\n",
    "                    batch_i,\n",
    "                    len(dataloader),\n",
    "                    model.losses[\"x\"],\n",
    "                    model.losses[\"y\"],\n",
    "                    model.losses[\"w\"],\n",
    "                    model.losses[\"h\"],\n",
    "                    model.losses[\"conf\"],\n",
    "                    model.losses[\"cls\"],\n",
    "                    loss.item(),\n",
    "                    model.losses[\"recall\"],\n",
    "                    model.losses[\"precision\"],\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            model.seen += imgs.size(0)\n",
    "            \n",
    "            #if batch_i==0:\n",
    "            #    break;\n",
    "            #print(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
